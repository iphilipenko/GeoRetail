#!/usr/bin/env python3
"""
Batch processing script V2 - –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–∏–º brand matching —Ç–∞ tracking –Ω–µ–≤—ñ–¥–æ–º–∏—Ö –±—Ä–µ–Ω–¥—ñ–≤
"""

import sys
from pathlib import Path
import psycopg2
from psycopg2.extras import RealDictCursor
import logging
from datetime import datetime
import uuid

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –î–æ–¥–∞—î–º–æ –ø–æ—Ç–æ—á–Ω—É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é –¥–æ path
sys.path.insert(0, str(Path(__file__).parent))

# –Ü–º–ø–æ—Ä—Ç–∏ –º–æ–¥—É–ª—ñ–≤
from normalization.tag_parser import TagParser
from normalization.brand_matcher import BrandMatcher
from normalization.brand_manager import BrandManager

# Database connection
DB_CONNECTION_STRING = "postgresql://georetail_user:georetail_secure_2024@localhost:5432/georetail"

class BatchProcessorV2:
    """–ü–æ–∫—Ä–∞—â–µ–Ω–∏–π –ø—Ä–æ—Ü–µ—Å–æ—Ä –∑ tracking –Ω–µ–≤—ñ–¥–æ–º–∏—Ö –±—Ä–µ–Ω–¥—ñ–≤"""
    
    def __init__(self, connection_string=None):
        self.connection_string = connection_string or DB_CONNECTION_STRING
        self.tag_parser = TagParser()
        
        # –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ brand matcher –∑ –≤–∏—â–∏–º threshold
        matcher_config = {
            'algorithms': {
                'exact': {'enabled': True, 'priority': 1},
                'fuzzy': {
                    'enabled': True, 
                    'priority': 2,
                    'threshold': 0.95,  # –ü—ñ–¥–≤–∏—â–µ–Ω–∏–π threshold!
                    'algorithm': 'token_sort_ratio'
                },
                'osm_tags': {'enabled': True, 'priority': 3},
                'keywords': {
                    'enabled': False,  # –í–∏–º–∫–Ω–µ–Ω–æ —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ false positives
                    'priority': 4,
                    'min_confidence': 0.8
                }
            },
            'cache': {
                'enabled': True,
                'max_size': 10000
            },
            'quality': {
                'min_confidence': 0.9,  # –í–∏—Å–æ–∫–∏–π –º—ñ–Ω—ñ–º—É–º!
                'auto_approve_threshold': 0.95
            }
        }
        
        self.brand_matcher = BrandMatcher(config=matcher_config)
        self.brand_manager = BrandManager(self.connection_string)
        
        self.stats = {
            'processed': 0,
            'poi_found': 0,
            'brands_matched': 0,
            'unknown_brands': 0,
            'errors': 0
        }
        
        # –î–ª—è tracking –Ω–µ–≤—ñ–¥–æ–º–∏—Ö –±—Ä–µ–Ω–¥—ñ–≤ –≤ batch
        self.unknown_brands = {}
    
    def process_batch(self, limit=1000, region=None, batch_size=1000):
        """–û–±—Ä–æ–±–∫–∞ batch –∑–∞–ø–∏—Å—ñ–≤ –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–∏–º error handling"""
        logger.info(f"üöÄ –ü–æ—á–∞—Ç–æ–∫ –æ–±—Ä–æ–±–∫–∏ batch V2 (limit={limit}, region={region})")
        
        conn = psycopg2.connect(self.connection_string)
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        try:
            # –í–∏–±–∏—Ä–∞—î–º–æ –¥–∞–Ω—ñ –¥–ª—è –æ–±—Ä–æ–±–∫–∏
            base_query = """
                SELECT id, osm_id, tags, name, brand, 
                       ST_AsText(geom) as geom_wkt,
                       h3_res_7, h3_res_8, h3_res_9, h3_res_10,
                       region_name
                FROM osm_ukraine.osm_raw
                WHERE tags IS NOT NULL
                AND (
                    tags::text LIKE '%%shop%%' 
                    OR tags::text LIKE '%%amenity%%'
                    OR tags::text LIKE '%%brand%%'
                )
                AND id NOT IN (
                    SELECT osm_raw_id FROM osm_ukraine.poi_processed 
                    WHERE osm_raw_id IS NOT NULL
                )
            """
            
            if region:
                query = base_query + f" AND region_name = '{region}' LIMIT {limit}"
                logger.info(f"üìä –í–∏–±—ñ—Ä–∫–∞ –¥–∞–Ω–∏—Ö –∑ —Ä–µ–≥—ñ–æ–Ω—É {region}...")
            else:
                query = base_query + f" LIMIT {limit}"
                logger.info(f"üìä –í–∏–±—ñ—Ä–∫–∞ –¥–∞–Ω–∏—Ö...")
            
            cur.execute(query)
            rows = cur.fetchall()
            logger.info(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(rows)} –Ω–æ–≤–∏—Ö –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è –æ–±—Ä–æ–±–∫–∏")
            
            # –û–±—Ä–æ–±–ª—è—î–º–æ –±–∞—Ç—á–∞–º–∏
            for i in range(0, len(rows), batch_size):
                batch = rows[i:i+batch_size]
                logger.info(f"  –û–±—Ä–æ–±–∫–∞ batch {i//batch_size + 1}/{(len(rows)-1)//batch_size + 1}")
                
                processed_entities = []
                
                for row in batch:
                    try:
                        entity = self.process_row(row)
                        if entity:
                            processed_entities.append(entity)
                            self.stats['poi_found'] += 1
                    except Exception as e:
                        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∑–∞–ø–∏—Å—É {row['id']}: {e}")
                        self.stats['errors'] += 1
                    
                    self.stats['processed'] += 1
                
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ batch
                if processed_entities:
                    self.save_entities(conn, processed_entities)
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –Ω–µ–≤—ñ–¥–æ–º—ñ –±—Ä–µ–Ω–¥–∏
            self.save_unknown_brands()
            
            # –í–∏–≤–æ–¥–∏–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.print_statistics()
            
        finally:
            cur.close()
            conn.close()
    
    def process_row(self, row):
        """–û–±—Ä–æ–±–∫–∞ –æ–¥–Ω–æ–≥–æ –∑–∞–ø–∏—Å—É –∑ tracking –Ω–µ–≤—ñ–¥–æ–º–∏—Ö –±—Ä–µ–Ω–¥—ñ–≤"""
        # –ü–∞—Ä—Å–∏–º–æ —Ç–µ–≥–∏
        parsed_tags = self.tag_parser.parse_tags(row['tags'])
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
        primary_cat, secondary_cat = self.tag_parser.get_category_from_tags(parsed_tags.tags)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –Ω–µ-POI
        if primary_cat in ['road', 'building', 'landuse', 'other']:
            return None
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –Ω–∞–∑–≤—É
        name = parsed_tags.name or row.get('name')
        if not name:
            return None
        
        # –ú–∞—Ç—á–∏–º–æ –±—Ä–µ–Ω–¥ –∑ –≤–∏—Å–æ–∫–∏–º threshold
        brand_result = self.brand_matcher.match_brand(
            name=name,
            osm_tags=parsed_tags.tags
        )
        
        # –Ø–∫—â–æ –±—Ä–µ–Ω–¥ –Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ –∞–±–æ –Ω–∏–∑—å–∫–∞ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å
        if not brand_result or brand_result.confidence < 0.9:
            # –ó–∞–ø–∏—Å—É—î–º–æ —è–∫ –Ω–µ–≤—ñ–¥–æ–º–∏–π –±—Ä–µ–Ω–¥
            self.track_unknown_brand(name, row['region_name'], primary_cat)
            
            # –°–∫–∏–¥–∞—î–º–æ brand result —è–∫—â–æ –Ω–∏–∑—å–∫–∞ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å
            if brand_result and brand_result.confidence < 0.9:
                logger.debug(f"–í—ñ–¥—Ö–∏–ª–µ–Ω–æ –Ω–µ—á—ñ—Ç–∫–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è: {name} -> {brand_result.canonical_name} (conf: {brand_result.confidence})")
                brand_result = None
        else:
            self.stats['brands_matched'] += 1
        
        # –§–æ—Ä–º—É—î–º–æ entity
        entity = {
            'entity_id': str(uuid.uuid4()),
            'osm_id': row['osm_id'],
            'osm_raw_id': row['id'],
            'entity_type': 'poi',
            'primary_category': primary_cat,
            'secondary_category': secondary_cat,
            'name_original': name,
            'name_standardized': name,
            'brand_normalized': brand_result.canonical_name if brand_result else None,
            'brand_confidence': brand_result.confidence if brand_result else 0.0,
            'brand_match_type': brand_result.match_type if brand_result else 'none',
            'functional_group': brand_result.functional_group if brand_result else self._get_default_group(primary_cat),
            'influence_weight': brand_result.influence_weight if brand_result else 0.0,
            'geom_wkt': row['geom_wkt'],
            'h3_res_7': row['h3_res_7'],
            'h3_res_8': row['h3_res_8'],
            'h3_res_9': row['h3_res_9'],
            'h3_res_10': row['h3_res_10'],
            'quality_score': 0.8 if brand_result else 0.5,
            'region_name': row['region_name'],
            'processing_timestamp': datetime.now(),
            'processing_version': '2.0.1'
        }
        
        return entity
    
    def track_unknown_brand(self, name, region, category):
        """–í—ñ–¥—Å—Ç–µ–∂—É—î –Ω–µ–≤—ñ–¥–æ–º—ñ –±—Ä–µ–Ω–¥–∏"""
        # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–≥–∞–ª—å–Ω—ñ –Ω–∞–∑–≤–∏
        generic_names = ['–ø—Ä–æ–¥—É–∫—Ç–∏', '–º–∞–≥–∞–∑–∏–Ω', '–∞–ø—Ç–µ–∫–∞', '–∫–∞—Ñ–µ', '—Ä–µ—Å—Ç–æ—Ä–∞–Ω', '–±–∞–Ω–∫']
        if name.lower() in generic_names:
            return
        
        if name not in self.unknown_brands:
            self.unknown_brands[name] = {
                'count': 0,
                'regions': set(),
                'categories': set()
            }
        
        self.unknown_brands[name]['count'] += 1
        self.unknown_brands[name]['regions'].add(region)
        self.unknown_brands[name]['categories'].add(category)
        self.stats['unknown_brands'] += 1
    
    def save_unknown_brands(self):
        """–ó–±–µ—Ä—ñ–≥–∞—î –Ω–µ–≤—ñ–¥–æ–º—ñ –±—Ä–µ–Ω–¥–∏ –≤ brand manager"""
        logger.info(f"\nüìù –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è {len(self.unknown_brands)} –Ω–µ–≤—ñ–¥–æ–º–∏—Ö –±—Ä–µ–Ω–¥—ñ–≤...")
        
        for name, data in self.unknown_brands.items():
            if data['count'] >= 2:  # –ú—ñ–Ω—ñ–º—É–º 2 –ø–æ—è–≤–∏
                for region in data['regions']:
                    self.brand_manager.record_unknown_brand(
                        name=name,
                        region=region,
                        category=list(data['categories'])[0] if data['categories'] else None
                    )
        
        # –í–∏–≤–æ–¥–∏–º–æ —Ç–æ–ø –Ω–µ–≤—ñ–¥–æ–º–∏—Ö –±—Ä–µ–Ω–¥—ñ–≤
        top_unknown = sorted(self.unknown_brands.items(), key=lambda x: x[1]['count'], reverse=True)[:10]
        
        if top_unknown:
            logger.info("\nüîç –¢–æ–ø-10 –Ω–µ–≤—ñ–¥–æ–º–∏—Ö –±—Ä–µ–Ω–¥—ñ–≤:")
            for name, data in top_unknown:
                logger.info(f"  - {name}: {data['count']} —Ä–∞–∑—ñ–≤")
    
    def save_entities(self, conn, entities):
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è entities –∑ proper error handling"""
        saved_count = 0
        
        insert_query = """
            INSERT INTO osm_ukraine.poi_processed (
                entity_id, osm_id, osm_raw_id, entity_type,
                primary_category, secondary_category,
                name_original, name_standardized,
                brand_normalized, brand_confidence, brand_match_type,
                functional_group, influence_weight,
                geom, h3_res_7, h3_res_8, h3_res_9, h3_res_10,
                quality_score, region_name,
                processing_timestamp, processing_version
            ) VALUES (
                %(entity_id)s, %(osm_id)s, %(osm_raw_id)s, %(entity_type)s,
                %(primary_category)s, %(secondary_category)s,
                %(name_original)s, %(name_standardized)s,
                %(brand_normalized)s, %(brand_confidence)s, %(brand_match_type)s,
                %(functional_group)s, %(influence_weight)s,
                ST_GeomFromText(%(geom_wkt)s, 4326),
                %(h3_res_7)s, %(h3_res_8)s, %(h3_res_9)s, %(h3_res_10)s,
                %(quality_score)s, %(region_name)s,
                %(processing_timestamp)s, %(processing_version)s
            )
            ON CONFLICT (entity_id) DO NOTHING
        """
        
        # –ö–æ–∂–µ–Ω –∑–∞–ø–∏—Å –≤ –æ–∫—Ä–µ–º—ñ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ—ó
        for entity in entities:
            try:
                cur = conn.cursor()
                cur.execute(insert_query, entity)
                conn.commit()
                cur.close()
                saved_count += 1
            except Exception as e:
                conn.rollback()
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è: {e}")
                logger.debug(f"Entity: {entity.get('name_original')}, Geom: {entity.get('geom_wkt')[:50]}")
        
        logger.info(f"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ {saved_count}/{len(entities)} entities")
    
    def _get_default_group(self, category):
        """–í–∏–∑–Ω–∞—á–∞—î —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—É –≥—Ä—É–ø—É –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º"""
        if category == 'retail':
            return 'competitor'
        elif category in ['food_service', 'financial', 'healthcare']:
            return 'traffic_generator'
        elif category == 'transport':
            return 'accessibility'
        else:
            return 'neutral'
    
    def print_statistics(self):
        """–í–∏–≤–æ–¥–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        logger.info("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–æ–±–∫–∏ V2:")
        logger.info(f"  –û–±—Ä–æ–±–ª–µ–Ω–æ –∑–∞–ø–∏—Å—ñ–≤: {self.stats['processed']:,}")
        logger.info(f"  –ó–Ω–∞–π–¥–µ–Ω–æ POI: {self.stats['poi_found']:,}")
        logger.info(f"  –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ –±—Ä–µ–Ω–¥—ñ–≤: {self.stats['brands_matched']:,}")
        logger.info(f"  –ù–µ–≤—ñ–¥–æ–º–∏—Ö –±—Ä–µ–Ω–¥—ñ–≤: {self.stats['unknown_brands']:,}")
        logger.info(f"  –ü–æ–º–∏–ª–æ–∫: {self.stats['errors']:,}")
        
        if self.stats['poi_found'] > 0:
            brand_rate = (self.stats['brands_matched'] / self.stats['poi_found']) * 100
            logger.info(f"  Brand recognition rate: {brand_rate:.1f}%")


def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Batch processing POI V2')
    parser.add_argument('--limit', type=int, default=1000, help='–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Å—ñ–≤')
    parser.add_argument('--region', type=str, help='–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π —Ä–µ–≥—ñ–æ–Ω')
    parser.add_argument('--batch-size', type=int, default=1000, help='–†–æ–∑–º—ñ—Ä batch')
    
    args = parser.parse_args()
    
    processor = BatchProcessorV2()
    processor.process_batch(
        limit=args.limit, 
        region=args.region,
        batch_size=args.batch_size
    )


if __name__ == "__main__":
    main()