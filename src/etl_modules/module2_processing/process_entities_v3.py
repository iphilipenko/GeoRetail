#!/usr/bin/env python3
"""
Process Entities V3 - Universal Entity Processing Pipeline
–†–æ–∑—à–∏—Ä–µ–Ω–Ω—è process_batch_v2.py –¥–ª—è –æ–±—Ä–æ–±–∫–∏ POI + Transport + Roads
"""

import sys
import json
import uuid
from pathlib import Path
import psycopg2
from psycopg2.extras import RealDictCursor
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –î–æ–¥–∞—î–º–æ –ø–æ—Ç–æ—á–Ω—É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é –¥–æ path
sys.path.insert(0, str(Path(__file__).parent))

# –Ü–º–ø–æ—Ä—Ç–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤ (–∑ —ñ—Å–Ω—É—é—á–∏—Ö —Ç–∞ –Ω–æ–≤–∏—Ö –º–æ–¥—É–ª—ñ–≤)
from normalization.tag_parser import TagParser
from normalization.brand_matcher import BrandMatcher
from normalization.entity_classifier import EntityClassifier

# Connection string
DB_CONNECTION_STRING = "postgresql://georetail_user:georetail_secure_2024@localhost:5432/georetail"

class EntityProcessorV3:
    """
    Universal Entity Processor - —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è V2 –¥–ª—è transport —Ç–∞ road entities
    """
    
    def __init__(self, connection_string=None):
        self.connection_string = connection_string or DB_CONNECTION_STRING
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
        self.tag_parser = TagParser()
        self.brand_matcher = BrandMatcher() 
        self.entity_classifier = EntityClassifier()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'processed': 0,
            'poi_found': 0,
            'transport_found': 0, 
            'road_found': 0,
            'brands_matched': 0,
            'errors': 0,
            'skipped': 0
        }
        
        # Functional group weights
        self.FUNCTIONAL_WEIGHTS = {
            # POI weights (–∑ —ñ—Å–Ω—É—é—á–æ—ó V2 –ª–æ–≥—ñ–∫–∏)
            'competitor': -0.8,
            'traffic_generator': 0.6,
            
            # Transport weights (–Ω–æ–≤—ñ)
            'accessibility': {
                'bus_stop': 0.4,
                'bus_station': 0.6, 
                'train_station': 0.8,
                'metro_station': 0.9,
                'tram_stop': 0.3,
                'transport_node': 0.4  # generic
            },
            
            # Road weights (–Ω–æ–≤—ñ) 
            'road_accessibility': {
                'motorway': 0.9,
                'trunk': 0.8,
                'primary': 0.7,
                'secondary': 0.6,
                'tertiary': 0.5,
                'residential': 0.2,
                'service': 0.1,
                'unclassified': 0.3
            }
        }
        
        logger.info("üöÄ EntityProcessorV3 —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ")
    
    def process_batch(self, limit=1000, region=None, batch_size=1000):
        """
        –ì–æ–ª–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è batch –æ–±—Ä–æ–±–∫–∏ –∑–∞–ø–∏—Å—ñ–≤
        –†–æ–∑—à–∏—Ä–µ–Ω–Ω—è process_batch_v2.py –ª–æ–≥—ñ–∫–∏
        """
        logger.info(f"üöÄ –ü–æ—á–∞—Ç–æ–∫ V3 –æ–±—Ä–æ–±–∫–∏ batch (limit={limit}, region={region})")
        
        conn = psycopg2.connect(self.connection_string)
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        try:
            # –í–∏–±–∏—Ä–∞—î–º–æ –¥–∞–Ω—ñ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ (—Ä–æ–∑—à–∏—Ä–µ–Ω–∏–π –∑–∞–ø–∏—Ç)
            base_query = """
                SELECT id, osm_id, tags, name, brand, 
                       ST_AsText(geom) as geom_wkt,
                       ST_GeometryType(geom) as geom_type,
                       h3_res_7, h3_res_8, h3_res_9, h3_res_10,
                       region_name
                FROM osm_ukraine.osm_raw
                WHERE tags IS NOT NULL
                AND (
                    tags::text LIKE '%%shop%%' 
                    OR tags::text LIKE '%%amenity%%'
                    OR tags::text LIKE '%%highway%%'
                    OR tags::text LIKE '%%public_transport%%'
                    OR tags::text LIKE '%%railway%%'
                    OR tags::text LIKE '%%brand%%'
                )
                AND id NOT IN (
                    SELECT osm_raw_id FROM osm_ukraine.poi_processed 
                    WHERE osm_raw_id IS NOT NULL
                )
            """
            
            if region:
                query = base_query + f" AND region_name = '{region}' LIMIT {limit}"
                logger.info(f"üìä –í–∏–±—ñ—Ä–∫–∞ –¥–∞–Ω–∏—Ö –∑ —Ä–µ–≥—ñ–æ–Ω—É {region}...")
            else:
                query = base_query + f" LIMIT {limit}"
                logger.info(f"üìä –í–∏–±—ñ—Ä–∫–∞ –¥–∞–Ω–∏—Ö...")
            
            cur.execute(query)
            rows = cur.fetchall()
            logger.info(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(rows)} –Ω–æ–≤–∏—Ö –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è V3 –æ–±—Ä–æ–±–∫–∏")
            
            # –û–±—Ä–æ–±–ª—è—î–º–æ –±–∞—Ç—á–∞–º–∏
            all_entities = []
            for i in range(0, len(rows), batch_size):
                batch = rows[i:i+batch_size]
                logger.info(f"  –û–±—Ä–æ–±–∫–∞ V3 batch {i//batch_size + 1}/{(len(rows)-1)//batch_size + 1} ({len(batch)} –∑–∞–ø–∏—Å—ñ–≤)")
                
                entities = self.process_records_batch(batch)
                all_entities.extend(entities)
                
                # –ü–µ—Ä—ñ–æ–¥–∏—á–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
                if len(all_entities) >= 500:
                    self.save_entities(conn, all_entities)
                    all_entities = []
            
            # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–∞–ª–∏—à–∫—ñ–≤
            if all_entities:
                self.save_entities(conn, all_entities)
            
            self.print_statistics()
            
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ V3 batch processing: {e}")
            conn.rollback()
        finally:
            cur.close()
            conn.close()
    
    def process_records_batch(self, records: List[Dict]) -> List[Dict]:
        """
        –û–±—Ä–æ–±–∫–∞ batch –∑–∞–ø–∏—Å—ñ–≤ –∑ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—î—é –ø–æ —Ç–∏–ø–∞—Ö
        """
        entities = []
        
        for record in records:
            try:
                self.stats['processed'] += 1
                
                # –ü–∞—Ä—Å–∏–º–æ —Å–∫–ª–∞–¥–Ω—ñ JSON —Ç–µ–≥–∏ –∑ osm_raw
                tags = self._parse_complex_tags(record.get('tags'))
                if not tags:
                    self.stats['skipped'] += 1
                    continue
                
                # –ö–ª–∞—Å–∏—Ñ—ñ–∫—É—î–º–æ entity type
                entity_type = self.entity_classifier.classify_entity_type(tags)
                if not entity_type:
                    self.stats['skipped'] += 1
                    continue
                
                # –û–±—Ä–æ–±–ª—è—î–º–æ –ø–æ —Ç–∏–ø—É
                if entity_type == 'poi':
                    entity = self.process_poi(record, tags)
                    if entity:
                        self.stats['poi_found'] += 1
                elif entity_type == 'transport_node':
                    entity = self.process_transport_node(record, tags)
                    if entity:
                        self.stats['transport_found'] += 1
                elif entity_type == 'road_segment':
                    entity = self.process_road_segment(record, tags)
                    if entity:
                        self.stats['road_found'] += 1
                else:
                    continue
                
                if entity:
                    entities.append(entity)
                    
            except Exception as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∑–∞–ø–∏—Å—É {record.get('id', 'unknown')}: {e}")
                self.stats['errors'] += 1
                continue
        
        return entities
    
    def process_poi(self, record: Dict, tags: Dict[str, str]) -> Optional[Dict]:
        """
        –û–±—Ä–æ–±–∫–∞ POI - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ—Å–Ω—É—é—á—É V2 –ª–æ–≥—ñ–∫—É –∑ –Ω–µ–∑–Ω–∞—á–Ω–∏–º–∏ –∑–º—ñ–Ω–∞–º–∏
        """
        try:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ—Å–Ω—É—é—á–∏–π brand matcher
            name = record.get('name') or tags.get('name', '')
            brand_result = None
            
            if name:
                brand_result = self.brand_matcher.match_brand(name, tags)
                if brand_result and brand_result.confidence > 0.8:
                    self.stats['brands_matched'] += 1
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó (—ñ—Å–Ω—É—é—á–∞ V2 –ª–æ–≥—ñ–∫–∞)
            primary_category, secondary_category = self._get_poi_categories(tags)
            
            # –§—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω–∞ –≥—Ä—É–ø–∞ (—ñ—Å–Ω—É—é—á–∞ –ª–æ–≥—ñ–∫–∞)
            functional_group = self._get_poi_functional_group(primary_category, secondary_category)
            influence_weight = self.FUNCTIONAL_WEIGHTS.get(functional_group, 0.0)
            
            entity = {
                'entity_id': str(uuid.uuid4()),
                'osm_id': record.get('osm_id'),
                'osm_raw_id': record.get('id'),
                'entity_type': 'poi',
                'primary_category': primary_category,
                'secondary_category': secondary_category,
                'name_original': name,
                'name_standardized': name,  # TODO: –¥–æ–¥–∞—Ç–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü—ñ—é
                'brand_normalized': brand_result.brand_name if brand_result else None,
                'brand_confidence': brand_result.confidence if brand_result else 0.0,
                'brand_match_type': brand_result.match_type if brand_result else 'none',
                'functional_group': functional_group,
                'influence_weight': influence_weight,
                'geom_wkt': record.get('geom_wkt'),
                'h3_res_7': record.get('h3_res_7'),
                'h3_res_8': record.get('h3_res_8'),
                'h3_res_9': record.get('h3_res_9'),
                'h3_res_10': record.get('h3_res_10'),
                'highway_type': None,
                'max_speed': None,
                'accessibility_score': None,
                'quality_score': 0.8,  # Default quality
                'region_name': record.get('region_name'),
                'processing_timestamp': datetime.now(),
                'processing_version': '3.0'
            }
            
            return entity
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ POI: {e}")
            return None
    
    def process_transport_node(self, record: Dict, tags: Dict[str, str]) -> Optional[Dict]:
        """
        –û–±—Ä–æ–±–∫–∞ Transport Node - –Ω–æ–≤–∞ –ª–æ–≥—ñ–∫–∞ –¥–ª—è V3
        """
        try:
            # –ù–∞–∑–≤–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–≥–æ –≤—É–∑–ª–∞
            name = record.get('name') or tags.get('name', '')
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø—ñ–¥—Ç–∏–ø —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É
            transport_subtype = self._get_transport_subtype(tags)
            
            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ accessibility score
            accessibility_score = self._calculate_transport_accessibility(tags, transport_subtype)
            
            # –§—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω–∞ –≥—Ä—É–ø–∞ —Ç–∞ –≤–∞–≥–∞
            functional_group = 'accessibility'
            influence_weight = self.FUNCTIONAL_WEIGHTS['accessibility'].get(
                transport_subtype, 
                self.FUNCTIONAL_WEIGHTS['accessibility']['transport_node']
            )
            
            entity = {
                'entity_id': str(uuid.uuid4()),
                'osm_id': record.get('osm_id'),
                'osm_raw_id': record.get('id'),
                'entity_type': 'transport_node',
                'primary_category': 'transport',
                'secondary_category': transport_subtype,
                'name_original': name,
                'name_standardized': name,
                'brand_normalized': None,  # Transport nodes –Ω–µ –º–∞—é—Ç—å –±—Ä–µ–Ω–¥—ñ–≤ –≤ –Ω–∞—à—ñ–π –ª–æ–≥—ñ—Ü—ñ
                'brand_confidence': 0.0,
                'brand_match_type': 'none',
                'functional_group': functional_group,
                'influence_weight': influence_weight,
                'geom_wkt': record.get('geom_wkt'),
                'h3_res_7': record.get('h3_res_7'),
                'h3_res_8': record.get('h3_res_8'),
                'h3_res_9': record.get('h3_res_9'),
                'h3_res_10': record.get('h3_res_10'),
                'highway_type': tags.get('highway') if tags.get('highway') == 'bus_stop' else None,
                'max_speed': None,
                'accessibility_score': accessibility_score,
                'quality_score': self._calculate_transport_quality(tags, name),
                'region_name': record.get('region_name'),
                'processing_timestamp': datetime.now(),
                'processing_version': '3.0'
            }
            
            return entity
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ transport node: {e}")
            return None
    
    def process_road_segment(self, record: Dict, tags: Dict[str, str]) -> Optional[Dict]:
        """
        –û–±—Ä–æ–±–∫–∞ Road Segment - –Ω–æ–≤–∞ –ª–æ–≥—ñ–∫–∞ –¥–ª—è V3
        """
        try:
            # –ù–∞–∑–≤–∞ –¥–æ—Ä–æ–≥–∏
            name = record.get('name') or tags.get('name', '')
            
            # –¢–∏–ø –¥–æ—Ä–æ–≥–∏
            highway_type = tags.get('highway', 'unclassified')
            road_subtype = self._get_road_subtype(tags)
            
            # –û–±–º–µ–∂–µ–Ω–Ω—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
            max_speed = self._parse_speed_limit(tags.get('maxspeed'))
            
            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ accessibility score
            accessibility_score = self._calculate_road_accessibility(tags, highway_type)
            
            # –§—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω–∞ –≥—Ä—É–ø–∞ —Ç–∞ –≤–∞–≥–∞
            functional_group = 'accessibility'
            influence_weight = self.FUNCTIONAL_WEIGHTS['road_accessibility'].get(
                road_subtype,
                self.FUNCTIONAL_WEIGHTS['road_accessibility']['unclassified']
            )
            
            entity = {
                'entity_id': str(uuid.uuid4()),
                'osm_id': record.get('osm_id'),
                'osm_raw_id': record.get('id'),
                'entity_type': 'road_segment',
                'primary_category': 'road',
                'secondary_category': road_subtype,
                'name_original': name,
                'name_standardized': name,
                'brand_normalized': None,  # Roads –Ω–µ –º–∞—é—Ç—å –±—Ä–µ–Ω–¥—ñ–≤
                'brand_confidence': 0.0,
                'brand_match_type': 'none',
                'functional_group': functional_group,
                'influence_weight': influence_weight,
                'geom_wkt': record.get('geom_wkt'),
                'h3_res_7': record.get('h3_res_7'),
                'h3_res_8': record.get('h3_res_8'),
                'h3_res_9': record.get('h3_res_9'),
                'h3_res_10': record.get('h3_res_10'),
                'highway_type': highway_type,
                'max_speed': max_speed,
                'accessibility_score': accessibility_score,
                'quality_score': self._calculate_road_quality(tags),
                'region_name': record.get('region_name'),
                'processing_timestamp': datetime.now(),
                'processing_version': '3.0'
            }
            
            return entity
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ road segment: {e}")
            return None
    
    def _parse_complex_tags(self, tags_field: Any) -> Dict[str, str]:
        """
        –ü–∞—Ä—Å–∏—Ç—å —Å–∫–ª–∞–¥–Ω—É JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑ osm_raw.tags
        –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –ª–æ–≥—ñ–∫—É –∑ TagParserExtension
        """
        if not tags_field:
            return {}
        
        try:
            if isinstance(tags_field, str):
                outer_json = json.loads(tags_field)
            elif isinstance(tags_field, dict):
                outer_json = tags_field
            else:
                return {}
            
            inner_tags_string = outer_json.get('tags', '{}')
            if not inner_tags_string or inner_tags_string == '{}':
                return {}
            
            inner_tags = json.loads(inner_tags_string)
            
            # –û—á–∏—â—É—î–º–æ —Ç–µ–≥–∏
            cleaned_tags = {}
            for key, value in inner_tags.items():
                if key and value is not None:
                    cleaned_key = str(key).strip()
                    cleaned_value = str(value).strip()
                    if cleaned_key and cleaned_value:
                        cleaned_tags[cleaned_key] = cleaned_value
            
            return cleaned_tags
            
        except Exception as e:
            logger.warning(f"Error parsing complex tags: {e}")
            return {}
    
    def _get_poi_categories(self, tags: Dict[str, str]) -> tuple:
        """
        –í–∏–∑–Ω–∞—á–∞—î POI –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ—Å–Ω—É—é—á—É V2 –ª–æ–≥—ñ–∫—É
        """
        if 'shop' in tags:
            return 'retail', tags['shop']
        
        if 'amenity' in tags:
            amenity = tags['amenity']
            if amenity in ['restaurant', 'cafe', 'fast_food', 'bar', 'pub']:
                return 'food_service', amenity
            elif amenity in ['pharmacy', 'hospital', 'clinic', 'doctors']:
                return 'healthcare', amenity
            elif amenity in ['school', 'university', 'kindergarten']:
                return 'education', amenity
            elif amenity in ['bank', 'atm']:
                return 'financial', amenity
            else:
                return 'amenity', amenity
        
        if 'office' in tags:
            return 'office', tags.get('office', 'company')
        
        return 'poi', 'unknown'
    
    def _get_poi_functional_group(self, primary_category: str, secondary_category: str) -> str:
        """
        –í–∏–∑–Ω–∞—á–∞—î —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—É –≥—Ä—É–ø—É POI - —ñ—Å–Ω—É—é—á–∞ V2 –ª–æ–≥—ñ–∫–∞
        """
        # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–∏ (—Ä–æ–∑–¥—Ä—ñ–±–Ω–∞ —Ç–æ—Ä–≥—ñ–≤–ª—è)
        if primary_category == 'retail':
            return 'competitor'
        
        # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∏ —Ç—Ä–∞—Ñ—ñ–∫—É
        if primary_category in ['food_service', 'healthcare', 'education']:
            return 'traffic_generator'
        
        return 'competitor'  # Default –¥–ª—è POI
    
    def _get_transport_subtype(self, tags: Dict[str, str]) -> str:
        """
        –í–∏–∑–Ω–∞—á–∞—î –ø—ñ–¥—Ç–∏–ø —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–≥–æ –≤—É–∑–ª–∞
        """
        if tags.get('highway') == 'bus_stop':
            return 'bus_stop'
        if tags.get('amenity') == 'bus_station':
            return 'bus_station'
        if tags.get('railway') == 'station':
            if tags.get('station') == 'subway':
                return 'metro_station'
            return 'train_station'
        if tags.get('railway') == 'halt':
            return 'train_halt'
        if tags.get('railway') in ['subway_entrance']:
            return 'metro_entrance'
        if tags.get('railway') == 'tram_stop':
            return 'tram_stop'
        if tags.get('amenity') == 'ferry_terminal':
            return 'ferry_terminal'
        if tags.get('amenity') == 'taxi':
            return 'taxi_stand'
        
        return 'transport_node'
    
    def _get_road_subtype(self, tags: Dict[str, str]) -> str:
        """
        –í–∏–∑–Ω–∞—á–∞—î –ø—ñ–¥—Ç–∏–ø –¥–æ—Ä–æ–≥–∏ –∑—ñ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü—ñ—î—é
        """
        highway_type = tags.get('highway', '').lower()
        
        highway_mapping = {
            'motorway': 'motorway',
            'motorway_link': 'motorway',
            'trunk': 'trunk', 
            'trunk_link': 'trunk',
            'primary': 'primary',
            'primary_link': 'primary',
            'secondary': 'secondary',
            'secondary_link': 'secondary', 
            'tertiary': 'tertiary',
            'tertiary_link': 'tertiary',
            'residential': 'residential',
            'living_street': 'residential',
            'service': 'service',
            'unclassified': 'unclassified',
            'track': 'track'
        }
        
        return highway_mapping.get(highway_type, 'unclassified')
    
    def _parse_speed_limit(self, maxspeed_value: Optional[str]) -> Optional[int]:
        """
        –ü–∞—Ä—Å–∏—Ç—å –æ–±–º–µ–∂–µ–Ω–Ω—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
        """
        if not maxspeed_value:
            return None
        
        maxspeed_str = str(maxspeed_value).strip().lower()
        
        # –°–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        if maxspeed_str in ['walk', 'walking']:
            return 5
        if maxspeed_str == 'none':
            return 130
        
        try:
            # –í–∏–¥–∞–ª—è—î–º–æ –æ–¥–∏–Ω–∏—Ü—ñ –≤–∏–º—ñ—Ä—É
            speed_str = maxspeed_str.replace('km/h', '').replace('kmh', '').strip()
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –º–∏–ª—ñ
            if 'mph' in maxspeed_str:
                speed_mph = float(speed_str.replace('mph', '').strip())
                return int(speed_mph * 1.60934)
            
            return int(float(speed_str))
            
        except (ValueError, TypeError):
            return None
    
    def _calculate_transport_accessibility(self, tags: Dict[str, str], transport_subtype: str) -> float:
        """
        –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ accessibility score –¥–ª—è transport node
        """
        base_scores = {
            'metro_station': 0.95,
            'train_station': 0.9,
            'bus_station': 0.8,
            'bus_stop': 0.6,
            'tram_stop': 0.5,
            'taxi_stand': 0.3,
            'transport_node': 0.4
        }
        
        base_score = base_scores.get(transport_subtype, 0.4)
        
        # –ë–æ–Ω—É—Å–∏ –∑–∞ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ –∞—Ç—Ä–∏–±—É—Ç–∏
        if tags.get('shelter') == 'yes':
            base_score += 0.1
        if tags.get('bench') == 'yes':
            base_score += 0.05
        if 'network' in tags:
            base_score += 0.05
        
        return min(base_score, 1.0)
    
    def _calculate_road_accessibility(self, tags: Dict[str, str], highway_type: str) -> float:
        """
        –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ accessibility score –¥–ª—è road segment
        """
        base_scores = {
            'motorway': 0.95,
            'trunk': 0.9,
            'primary': 0.8,
            'secondary': 0.7,
            'tertiary': 0.6,
            'residential': 0.4,
            'service': 0.2,
            'unclassified': 0.3
        }
        
        base_score = base_scores.get(highway_type, 0.3)
        
        # –ë–æ–Ω—É—Å–∏ –∑–∞ —è–∫—ñ—Å—Ç—å –¥–æ—Ä–æ–≥–∏
        if tags.get('surface') == 'asphalt':
            base_score += 0.05
        elif tags.get('surface') in ['concrete', 'paved']:
            base_score += 0.03
        
        # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Å–º—É–≥
        try:
            lanes = int(tags.get('lanes', '1'))
            if lanes >= 4:
                base_score += 0.1
            elif lanes >= 2:
                base_score += 0.05
        except ValueError:
            pass
        
        return min(base_score, 1.0)
    
    def _calculate_transport_quality(self, tags: Dict[str, str], name: str) -> float:
        """
        –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ quality score –¥–ª—è transport node
        """
        quality = 0.5  # Base quality
        
        # –ù–∞–∑–≤–∞ –ø—ñ–¥–≤–∏—â—É—î —è–∫—ñ—Å—Ç—å
        if name and len(name) > 3:
            quality += 0.3
        
        # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –∞—Ç—Ä–∏–±—É—Ç–∏
        quality_tags = ['shelter', 'bench', 'network', 'operator']
        for tag in quality_tags:
            if tag in tags:
                quality += 0.05
        
        return min(quality, 1.0)
    
    def _calculate_road_quality(self, tags: Dict[str, str]) -> float:
        """
        –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ quality score –¥–ª—è road segment
        """
        quality = 0.6  # Base quality
        
        # –ê—Ç—Ä–∏–±—É—Ç–∏ —è–∫–æ—Å—Ç—ñ
        if 'maxspeed' in tags:
            quality += 0.1
        if 'surface' in tags:
            quality += 0.1
        if 'lanes' in tags:
            quality += 0.1
        if 'ref' in tags:  # –ù–æ–º–µ—Ä –¥–æ—Ä–æ–≥–∏
            quality += 0.1
        
        return min(quality, 1.0)
    
    def save_entities(self, conn, entities: List[Dict]):
        """
        –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è entities –≤ poi_processed - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ V2 –ª–æ–≥—ñ–∫—É
        """
        if not entities:
            return
        
        cur = conn.cursor()
        saved_count = 0
        
        insert_query = """
            INSERT INTO osm_ukraine.poi_processed (
                entity_id, osm_id, osm_raw_id, entity_type,
                primary_category, secondary_category,
                name_original, name_standardized,
                brand_normalized, brand_confidence, brand_match_type,
                functional_group, influence_weight,
                geom, h3_res_7, h3_res_8, h3_res_9, h3_res_10,
                highway_type, max_speed, accessibility_score,
                quality_score, region_name,
                processing_timestamp, processing_version
            ) VALUES (
                %(entity_id)s, %(osm_id)s, %(osm_raw_id)s, %(entity_type)s,
                %(primary_category)s, %(secondary_category)s,
                %(name_original)s, %(name_standardized)s,
                %(brand_normalized)s, %(brand_confidence)s, %(brand_match_type)s,
                %(functional_group)s, %(influence_weight)s,
                ST_GeomFromText(%(geom_wkt)s, 4326),
                %(h3_res_7)s, %(h3_res_8)s, %(h3_res_9)s, %(h3_res_10)s,
                %(highway_type)s, %(max_speed)s, %(accessibility_score)s,
                %(quality_score)s, %(region_name)s,
                %(processing_timestamp)s, %(processing_version)s
            )
            ON CONFLICT (entity_id) DO NOTHING
        """
        
        for entity in entities:
            try:
                cur.execute(insert_query, entity)
                saved_count += 1
            except Exception as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è entity {entity.get('entity_id', 'unknown')}: {e}")
                conn.rollback()
                cur = conn.cursor()
        
        conn.commit()
        cur.close()
        logger.info(f"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ {saved_count}/{len(entities)} V3 entities")
    
    def print_statistics(self):
        """
        –í–∏–≤–æ–¥–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É V3 –æ–±—Ä–æ–±–∫–∏
        """
        logger.info("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ V3 –æ–±—Ä–æ–±–∫–∏:")
        logger.info(f"  –û–±—Ä–æ–±–ª–µ–Ω–æ –∑–∞–ø–∏—Å—ñ–≤: {self.stats['processed']:,}")
        logger.info(f"  –ó–Ω–∞–π–¥–µ–Ω–æ POI: {self.stats['poi_found']:,}")
        logger.info(f"  –ó–Ω–∞–π–¥–µ–Ω–æ Transport: {self.stats['transport_found']:,}")
        logger.info(f"  –ó–Ω–∞–π–¥–µ–Ω–æ Roads: {self.stats['road_found']:,}")
        logger.info(f"  –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ –±—Ä–µ–Ω–¥—ñ–≤: {self.stats['brands_matched']:,}")
        logger.info(f"  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {self.stats['skipped']:,}")
        logger.info(f"  –ü–æ–º–∏–ª–æ–∫: {self.stats['errors']:,}")
        
        total_found = self.stats['poi_found'] + self.stats['transport_found'] + self.stats['road_found']
        if self.stats['processed'] > 0:
            success_rate = (total_found / self.stats['processed']) * 100
            logger.info(f"  Success rate: {success_rate:.1f}%")

def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description='V3 Universal Entity Processing')
    parser.add_argument('--limit', type=int, default=1000, help='–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Å—ñ–≤')
    parser.add_argument('--region', type=str, help='–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π —Ä–µ–≥—ñ–æ–Ω')
    parser.add_argument('--batch-size', type=int, default=1000, help='–†–æ–∑–º—ñ—Ä batch')
    
    args = parser.parse_args()
    
    processor = EntityProcessorV3()
    processor.process_batch(
        limit=args.limit, 
        region=args.region,
        batch_size=args.batch_size
    )

if __name__ == "__main__":
    main()