"""
Brand Matcher
–Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π –º–∞—Ç—á–∏–Ω–≥ –±—Ä–µ–Ω–¥—ñ–≤ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º multiple algorithms
"""

import re
import logging
from typing import Dict, Optional, Tuple, List, Any
from dataclasses import dataclass
from difflib import SequenceMatcher
from collections import defaultdict

# Optional: fuzzy matching library
try:
    from fuzzywuzzy import fuzz
    FUZZY_AVAILABLE = True
except ImportError:
    FUZZY_AVAILABLE = False
    logging.warning("fuzzywuzzy not installed, fuzzy matching will be limited")

from .brand_dictionary import BrandDictionary, BrandInfo

logger = logging.getLogger(__name__)


@dataclass
class MatchResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –º–∞—Ç—á–∏–Ω–≥—É –±—Ä–µ–Ω–¥—É"""
    brand_id: str
    canonical_name: str
    confidence: float
    match_type: str  # exact, fuzzy, osm_tag, keyword, generic
    functional_group: str
    influence_weight: float
    debug_info: Optional[Dict[str, Any]] = None


class BrandMatcher:
    """–ú–∞—Ç—á–∏–Ω–≥ –±—Ä–µ–Ω–¥—ñ–≤ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º —Ä—ñ–∑–Ω–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.brand_dict = BrandDictionary()
        self.config = config or self._default_config()
        
        # –ö–µ—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        self.cache = {} if self.config['cache']['enabled'] else None
        self.cache_hits = 0
        self.cache_misses = 0
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = defaultdict(int)
        
        # –ü–æ–±—É–¥–æ–≤–∞ –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤
        self._build_indexes()
    
    def _default_config(self) -> Dict[str, Any]:
        """–ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º"""
        return {
            'algorithms': {
                'exact': {'enabled': True, 'priority': 1},
                'fuzzy': {
                    'enabled': True, 
                    'priority': 2,
                    'threshold': 0.9,
                    'algorithm': 'token_sort_ratio'
                },
                'osm_tags': {'enabled': True, 'priority': 3},
                'keywords': {
                    'enabled': False,
                    'priority': 4,
                    'min_confidence': 0.8
                }
            },
            'cache': {
                'enabled': True,
                'max_size': 10000
            },
            'quality': {
                'min_confidence': 0.8,
                'auto_approve_threshold': 0.9
            }
        }
    
    def _build_indexes(self):
        """–ë—É–¥—É—î –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —ñ–Ω–¥–µ–∫—Å–∏ –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –ø–æ—à—É–∫—É"""
        # –Ü–Ω–¥–µ–∫—Å –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤
        self.keyword_index = defaultdict(list)
        
        # –Ü–Ω–¥–µ–∫—Å OSM —Ç–µ–≥—ñ–≤
        self.osm_tag_index = defaultdict(list)
        
        for brand_id, brand_info in self.brand_dict.brands.items():
            # –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –∑ –Ω–∞–∑–≤–∏
            keywords = self._extract_keywords(brand_info.canonical_name)
            for keyword in keywords:
                self.keyword_index[keyword].append(brand_id)
            
            # OSM —Ç–µ–≥–∏
            if brand_info.osm_tags:
                for tag in brand_info.osm_tags:
                    self.osm_tag_index[tag].append(brand_id)
    
    def match_brand(
        self, 
        name: Optional[str], 
        osm_tags: Optional[Dict[str, str]] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> Optional[MatchResult]:
        """
        –û—Å–Ω–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥ –º–∞—Ç—á–∏–Ω–≥—É –±—Ä–µ–Ω–¥—É
        
        Args:
            name: –ù–∞–∑–≤–∞ –¥–ª—è –ø–æ—à—É–∫—É
            osm_tags: OSM —Ç–µ–≥–∏ –æ–±'—î–∫—Ç–∞
            context: –î–æ–¥–∞—Ç–∫–æ–≤–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–∫–∞—Ç–µ–≥–æ—Ä—ñ—è, –ª–æ–∫–∞—Ü—ñ—è —Ç–æ—â–æ)
            
        Returns:
            MatchResult –∞–±–æ None —è–∫—â–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ
        """
        self.stats['total_requests'] += 1
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–µ—à—É
        cache_key = self._get_cache_key(name, osm_tags)
        if self.cache is not None and cache_key in self.cache:
            self.cache_hits += 1
            self.stats['cache_hits'] += 1
            return self.cache[cache_key]
        
        self.cache_misses += 1
        
        # –°–ø—Ä–æ–±—É–≤–∞—Ç–∏ —Ä—ñ–∑–Ω—ñ –∞–ª–≥–æ—Ä–∏—Ç–º–∏ –∑–∞ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–æ–º
        result = None
        
        if name and self.config['algorithms']['exact']['enabled']:
            result = self._exact_match(name)
            
        if not result and name and self.config['algorithms']['fuzzy']['enabled']:
            result = self._fuzzy_match(name)
            
        if not result and osm_tags and self.config['algorithms']['osm_tags']['enabled']:
            result = self._osm_tag_match(osm_tags, name)
            
        if not result and name and self.config['algorithms']['keywords']['enabled']:
            result = self._keyword_match(name, context)
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–æ—ó –¥–æ–≤—ñ—Ä–∏
        if result and result.confidence < self.config['quality']['min_confidence']:
            logger.debug(f"Match rejected due to low confidence: {result.confidence}")
            result = None
        
        # –ó–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –≤ –∫–µ—à
        if self.cache is not None and len(self.cache) < self.config['cache']['max_size']:
            self.cache[cache_key] = result
        
        # –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        if result:
            self.stats['successful_matches'] += 1
            self.stats[f'match_type_{result.match_type}'] += 1
        else:
            self.stats['failed_matches'] += 1
        
        return result
    
    def _exact_match(self, name: str) -> Optional[MatchResult]:
        """–¢–æ—á–Ω–∏–π –∑–±—ñ–≥ –∑ —Å–∏–Ω–æ–Ω—ñ–º–∞–º–∏"""
        result = self.brand_dict.find_brand_by_name(name)
        
        if result:
            brand_id, brand_info = result
            return MatchResult(
                brand_id=brand_id,
                canonical_name=brand_info.canonical_name,
                confidence=1.0,
                match_type='exact',
                functional_group=brand_info.functional_group,
                influence_weight=brand_info.influence_weight
            )
        
        return None
    
    def _fuzzy_match(self, name: str) -> Optional[MatchResult]:
        """–ù–µ—á—ñ—Ç–∫–∏–π –ø–æ—à—É–∫ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º fuzzy matching"""
        if not FUZZY_AVAILABLE:
            return self._simple_fuzzy_match(name)
        
        threshold = self.config['algorithms']['fuzzy']['threshold']
        algorithm = self.config['algorithms']['fuzzy']['algorithm']
        
        best_match = None
        best_score = 0
        best_brand_id = None
        
        # –ü–µ—Ä–µ–±–∏—Ä–∞—î–º–æ –≤—Å—ñ –±—Ä–µ–Ω–¥–∏
        for brand_id, brand_info in self.brand_dict.brands.items():
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–∞–Ω–æ–Ω—ñ—á–Ω—É –Ω–∞–∑–≤—É —Ç–∞ —Å–∏–Ω–æ–Ω—ñ–º–∏
            all_names = [brand_info.canonical_name] + brand_info.synonyms
            
            for brand_name in all_names:
                # –†—ñ–∑–Ω—ñ –∞–ª–≥–æ—Ä–∏—Ç–º–∏ fuzzy matching
                if algorithm == 'token_sort_ratio':
                    score = fuzz.token_sort_ratio(name, brand_name) / 100.0
                elif algorithm == 'token_set_ratio':
                    score = fuzz.token_set_ratio(name, brand_name) / 100.0
                elif algorithm == 'partial_ratio':
                    score = fuzz.partial_ratio(name, brand_name) / 100.0
                else:
                    score = fuzz.ratio(name, brand_name) / 100.0
                
                if score > best_score and score >= threshold:
                    best_score = score
                    best_match = brand_info
                    best_brand_id = brand_id
        
        if best_match:
            return MatchResult(
                brand_id=best_brand_id,
                canonical_name=best_match.canonical_name,
                confidence=best_score,
                match_type='fuzzy',
                functional_group=best_match.functional_group,
                influence_weight=best_match.influence_weight,
                debug_info={'algorithm': algorithm, 'score': best_score}
            )
        
        return None
    
    def _simple_fuzzy_match(self, name: str) -> Optional[MatchResult]:
        """–ü—Ä–æ—Å—Ç–∏–π fuzzy matching –±–µ–∑ –∑–æ–≤–Ω—ñ—à–Ω—ñ—Ö –±—ñ–±–ª—ñ–æ—Ç–µ–∫"""
        threshold = self.config['algorithms']['fuzzy']['threshold']
        
        best_match = None
        best_score = 0
        best_brand_id = None
        
        normalized_name = self._normalize_for_fuzzy(name)
        
        for brand_id, brand_info in self.brand_dict.brands.items():
            all_names = [brand_info.canonical_name] + brand_info.synonyms
            
            for brand_name in all_names:
                normalized_brand = self._normalize_for_fuzzy(brand_name)
                
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ SequenceMatcher
                score = SequenceMatcher(None, normalized_name, normalized_brand).ratio()
                
                # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –±–∞–ª–∏ –∑–∞ —Å–ø—ñ–ª—å–Ω—ñ —Å–ª–æ–≤–∞
                name_words = set(normalized_name.split())
                brand_words = set(normalized_brand.split())
                common_words = name_words.intersection(brand_words)
                
                if common_words:
                    word_bonus = len(common_words) / max(len(name_words), len(brand_words))
                    score = score * 0.7 + word_bonus * 0.3
                
                if score > best_score and score >= threshold:
                    best_score = score
                    best_match = brand_info
                    best_brand_id = brand_id
        
        if best_match:
            return MatchResult(
                brand_id=best_brand_id,
                canonical_name=best_match.canonical_name,
                confidence=best_score,
                match_type='fuzzy',
                functional_group=best_match.functional_group,
                influence_weight=best_match.influence_weight
            )
        
        return None
    
    def _osm_tag_match(self, osm_tags: Dict[str, str], name: Optional[str] = None) -> Optional[MatchResult]:
        """–ú–∞—Ç—á–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤—ñ OSM —Ç–µ–≥—ñ–≤"""
        candidates = defaultdict(float)
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ brand —Ç–µ–≥—É
        if 'brand' in osm_tags:
            brand_result = self.brand_dict.find_brand_by_name(osm_tags['brand'])
            if brand_result:
                brand_id, brand_info = brand_result
                candidates[brand_id] += 0.8
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ brand:wikidata
        if 'brand:wikidata' in osm_tags:
            # TODO: –ú–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ mapping wikidata -> brand_id
            pass
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ shop/amenity —Ç–∏–ø—ñ–≤
        shop_type = osm_tags.get('shop')
        amenity_type = osm_tags.get('amenity')
        
        # –ü–æ—à—É–∫ –∑–∞ OSM —Ç–µ–≥–∞–º–∏ –≤ —ñ–Ω–¥–µ–∫—Å—ñ
        for tag_key, tag_value in osm_tags.items():
            tag_pattern = f"{tag_key}={tag_value}"
            if tag_pattern in self.osm_tag_index:
                for brand_id in self.osm_tag_index[tag_pattern]:
                    candidates[brand_id] += 0.5
        
        # –Ø–∫—â–æ —î –Ω–∞–∑–≤–∞, –¥–æ–¥–∞—î–º–æ –¥–æ–¥–∞—Ç–∫–æ–≤—É –ø–µ—Ä–µ–≤—ñ—Ä–∫—É
        if name and candidates:
            for brand_id in list(candidates.keys()):
                brand_info = self.brand_dict.get_brand_by_id(brand_id)
                if brand_info:
                    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ö–æ–∂–æ—Å—Ç—ñ –Ω–∞–∑–≤–∏
                    name_similarity = self._calculate_name_similarity(name, brand_info.canonical_name)
                    candidates[brand_id] += name_similarity * 0.3
        
        # –í–∏–±–∏—Ä–∞—î–º–æ –Ω–∞–π–∫—Ä–∞—â–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        if candidates:
            best_brand_id = max(candidates, key=candidates.get)
            confidence = min(candidates[best_brand_id], 1.0)
            
            if confidence >= 0.5:  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –ø–æ—Ä—ñ–≥ –¥–ª—è OSM tag match
                brand_info = self.brand_dict.get_brand_by_id(best_brand_id)
                return MatchResult(
                    brand_id=best_brand_id,
                    canonical_name=brand_info.canonical_name,
                    confidence=confidence,
                    match_type='osm_tag',
                    functional_group=brand_info.functional_group,
                    influence_weight=brand_info.influence_weight,
                    debug_info={'osm_tags': osm_tags}
                )
        
        return None
    
    def _keyword_match(self, name: str, context: Optional[Dict[str, Any]] = None) -> Optional[MatchResult]:
        """–ú–∞—Ç—á–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤"""
        keywords = self._extract_keywords(name)
        if not keywords:
            return None
        
        candidates = defaultdict(float)
        
        # –ü–æ—à—É–∫ –∑–∞ –∫–ª—é—á–æ–≤–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
        for keyword in keywords:
            if keyword in self.keyword_index:
                for brand_id in self.keyword_index[keyword]:
                    candidates[brand_id] += 1.0 / len(keywords)
        
        # –í—Ä–∞—Ö–æ–≤—É—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç (—è–∫—â–æ —î)
        if context and 'category' in context:
            category = context['category']
            # –î–æ–¥–∞—î–º–æ –±–æ–Ω—É—Å –±—Ä–µ–Ω–¥–∞–º –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—é –∫–∞—Ç–µ–≥–æ—Ä—ñ—î—é
            for brand_id in candidates:
                brand_info = self.brand_dict.get_brand_by_id(brand_id)
                if brand_info and self._category_matches(category, brand_info.format):
                    candidates[brand_id] *= 1.2
        
        # –í–∏–±–∏—Ä–∞—î–º–æ –Ω–∞–π–∫—Ä–∞—â–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        if candidates:
            best_brand_id = max(candidates, key=candidates.get)
            confidence = candidates[best_brand_id] * self.config['algorithms']['keywords']['min_confidence']
            
            if confidence >= self.config['algorithms']['keywords']['min_confidence']:
                brand_info = self.brand_dict.get_brand_by_id(best_brand_id)
                return MatchResult(
                    brand_id=best_brand_id,
                    canonical_name=brand_info.canonical_name,
                    confidence=min(confidence, 0.8),  # –û–±–º–µ–∂—É—î–º–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É –¥–æ–≤—ñ—Ä—É
                    match_type='keyword',
                    functional_group=brand_info.functional_group,
                    influence_weight=brand_info.influence_weight,
                    debug_info={'keywords': keywords}
                )
        
        return None
    
    def _normalize_for_fuzzy(self, text: str) -> str:
        """–ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–µ–∫—Å—Ç—É –¥–ª—è fuzzy matching"""
        if not text:
            return ""
        
        # –ù–∏–∂–Ω—ñ–π —Ä–µ–≥—ñ—Å—Ç—Ä
        text = text.lower()
        
        # –í–∏–¥–∞–ª—è—î–º–æ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ —Å–∏–º–≤–æ–ª–∏
        text = re.sub(r'[^\w\s-]', ' ', text)
        
        # –ó–∞–º—ñ–Ω—é—î–º–æ –º–Ω–æ–∂–∏–Ω–Ω—ñ –ø—Ä–æ–±—ñ–ª–∏
        text = ' '.join(text.split())
        
        return text.strip()
    
    def _extract_keywords(self, text: str) -> List[str]:
        """–í–∏—Ç—è–≥—É—î –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –∑ —Ç–µ–∫—Å—Ç—É"""
        if not text:
            return []
        
        # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
        text = self._normalize_for_fuzzy(text)
        
        # –†–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞ —Å–ª–æ–≤–∞
        words = text.split()
        
        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –∫–æ—Ä–æ—Ç–∫—ñ —Å–ª–æ–≤–∞ —Ç–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
        stop_words = {'—Ç–∞', '—ñ', '–∞–±–æ', 'the', 'and', 'or', 'of', '–º–∞–≥–∞–∑–∏–Ω', '–º–∞—Ä–∫–µ—Ç'}
        keywords = [w for w in words if len(w) > 2 and w not in stop_words]
        
        return keywords
    
    def _calculate_name_similarity(self, name1: str, name2: str) -> float:
        """–†–æ–∑—Ä–∞—Ö–æ–≤—É—î —Å—Ö–æ–∂—ñ—Å—Ç—å –¥–≤–æ—Ö –Ω–∞–∑–≤"""
        norm1 = self._normalize_for_fuzzy(name1)
        norm2 = self._normalize_for_fuzzy(name2)
        
        return SequenceMatcher(None, norm1, norm2).ratio()
    
    def _category_matches(self, category: str, brand_format: str) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó —Ñ–æ—Ä–º–∞—Ç—É –±—Ä–µ–Ω–¥—É"""
        category_mappings = {
            'supermarket': ['—Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç', '–≥—ñ–ø–µ—Ä–º–∞—Ä–∫–µ—Ç', '–¥–∏—Å–∫–∞—É–Ω—Ç–µ—Ä'],
            'convenience': ['–º–∞–≥–∞–∑–∏–Ω –±—ñ–ª—è –¥–æ–º—É', '–º—ñ–Ω—ñ-–º–∞—Ä–∫–µ—Ç'],
            'electronics': ['–º–∞–≥–∞–∑–∏–Ω –µ–ª–µ–∫—Ç—Ä–æ–Ω—ñ–∫–∏', '–ø–æ–±—É—Ç–æ–≤–∞ —Ç–µ—Ö–Ω—ñ–∫–∞'],
            'clothing': ['–º–∞–≥–∞–∑–∏–Ω –æ–¥—è–≥—É', 'fashion'],
            'pharmacy': ['–∞–ø—Ç–µ–∫–∞', '–¥—Ä–æ–≥–µ—Ä—ñ'],
            'bank': ['–±–∞–Ω–∫', '—Ñ—ñ–Ω–∞–Ω—Å–æ–≤–∞ —É—Å—Ç–∞–Ω–æ–≤–∞'],
            'restaurant': ['—Ä–µ—Å—Ç–æ—Ä–∞–Ω', '–∫–∞–≤\'—è—Ä–Ω—è', '—Ñ–∞—Å—Ç—Ñ—É–¥', '–ø—ñ—Ü–µ—Ä—ñ—è']
        }
        
        for cat_key, formats in category_mappings.items():
            if category == cat_key and brand_format in formats:
                return True
        
        return False
    
    def _get_cache_key(self, name: Optional[str], osm_tags: Optional[Dict[str, str]]) -> str:
        """–ì–µ–Ω–µ—Ä—É—î –∫–ª—é—á –¥–ª—è –∫–µ—à—É"""
        parts = []
        
        if name:
            parts.append(f"name:{self._normalize_for_fuzzy(name)}")
        
        if osm_tags:
            # –°–æ—Ä—Ç—É—î–º–æ —Ç–µ–≥–∏ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—ñ
            tag_str = ','.join(f"{k}={v}" for k, v in sorted(osm_tags.items()) if k in ['shop', 'amenity', 'brand'])
            if tag_str:
                parts.append(f"tags:{tag_str}")
        
        return '|'.join(parts)
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–≤–µ—Ä—Ç–∞—î —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–æ–±–æ—Ç–∏ matcher"""
        total_matches = self.stats['successful_matches'] + self.stats['failed_matches']
        success_rate = self.stats['successful_matches'] / total_matches if total_matches > 0 else 0
        
        cache_total = self.cache_hits + self.cache_misses
        cache_hit_rate = self.cache_hits / cache_total if cache_total > 0 else 0
        
        return {
            'total_requests': self.stats['total_requests'],
            'successful_matches': self.stats['successful_matches'],
            'failed_matches': self.stats['failed_matches'],
            'success_rate': success_rate,
            'match_types': {
                'exact': self.stats.get('match_type_exact', 0),
                'fuzzy': self.stats.get('match_type_fuzzy', 0),
                'osm_tag': self.stats.get('match_type_osm_tag', 0),
                'keyword': self.stats.get('match_type_keyword', 0)
            },
            'cache_hits': self.cache_hits,
            'cache_misses': self.cache_misses,
            'cache_hit_rate': cache_hit_rate,
            'cache_size': len(self.cache) if self.cache else 0
        }
    
    def clear_cache(self):
        """–û—á–∏—â–∞—î –∫–µ—à"""
        if self.cache is not None:
            self.cache.clear()
        self.cache_hits = 0
        self.cache_misses = 0


# –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è
if __name__ == "__main__":
    # –°—Ç–≤–æ—Ä—é—î–º–æ matcher
    matcher = BrandMatcher()
    
    # –¢–µ—Å—Ç–æ–≤—ñ –≤–∏–ø–∞–¥–∫–∏
    test_cases = [
        # (name, osm_tags, expected_brand)
        ("–ê–¢–ë-–º–∞—Ä–∫–µ—Ç", None, "–ê–¢–ë-–ú–∞—Ä–∫–µ—Ç"),
        ("—Å–∏–ª–ø–æ", None, "–°—ñ–ª—å–ø–æ"),
        ("–ï–ü–Ü–¶–ï–ù–¢–†", None, "–ï–ø—ñ—Ü–µ–Ω—Ç—Ä –ö"),
        ("–ê–ø—Ç–µ–∫–∞ EVA", None, "EVA"),
        ("–ù–æ–≤–∞ –ø–æ—à—Ç–∞ ‚Ññ123", None, "–ù–æ–≤–∞ –ü–æ—à—Ç–∞"),
        ("McDonald's", {"amenity": "fast_food", "brand": "McDonald's"}, "McDonald's"),
        ("–°—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç Novus", {"shop": "supermarket"}, "Novus"),
        ("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–∞–≥–∞–∑–∏–Ω", None, None)
    ]
    
    print("üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è Brand Matcher:\n")
    
    for name, tags, expected in test_cases:
        result = matcher.match_brand(name, tags)
        
        if result:
            print(f"‚úÖ '{name}' ‚Üí {result.canonical_name}")
            print(f"   –î–æ–≤—ñ—Ä–∞: {result.confidence:.2f}, –¢–∏–ø: {result.match_type}")
            print(f"   –í–ø–ª–∏–≤: {result.influence_weight}, –ì—Ä—É–ø–∞: {result.functional_group}")
        else:
            print(f"‚ùå '{name}' ‚Üí –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
        print()
    
    # –í–∏–≤–æ–¥–∏–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = matcher.get_statistics()
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  –í—Å—å–æ–≥–æ –∑–∞–ø–∏—Ç—ñ–≤: {stats['total_requests']}")
    print(f"  –£—Å–ø—ñ—à–Ω–∏—Ö: {stats['successful_matches']} ({stats['success_rate']*100:.1f}%)")
    print(f"  –¢–∏–ø–∏ –º–∞—Ç—á–∏–Ω–≥—É: {stats['match_types']}")
    print(f"  Cache hit rate: {stats['cache_hit_rate']*100:.1f}%")