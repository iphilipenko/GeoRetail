#!/usr/bin/env python3
"""
Test script –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ä–æ–±–æ—Ç–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤ Module 2
"""

import sys
from pathlib import Path

# –î–æ–¥–∞—î–º–æ –ø–æ—Ç–æ—á–Ω—É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é –¥–æ Python path
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# –Ü–º–ø–æ—Ä—Ç—É—î–º–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –Ω–∞–ø—Ä—è–º—É –∑ –ª–æ–∫–∞–ª—å–Ω–∏—Ö –º–æ–¥—É–ª—ñ–≤
try:
    from normalization.tag_parser import TagParser
    from normalization.brand_dictionary import BrandDictionary
    from normalization.brand_matcher import BrandMatcher
    print("‚úÖ –Ü–º–ø–æ—Ä—Ç–∏ —É—Å–ø—ñ—à–Ω—ñ!")
except ImportError as e:
    print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —ñ–º–ø–æ—Ä—Ç—É: {e}")
    print(f"–ü–æ—Ç–æ—á–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è: {current_dir}")
    print(f"Python path: {sys.path[:3]}")
    sys.exit(1)

def test_tag_parser():
    """–¢–µ—Å—Ç Tag Parser"""
    print("\nüß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è Tag Parser...")
    
    parser = TagParser()
    
    # –¢–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ
    test_cases = [
        {"tags": '{"shop": "supermarket", "name": "–ê–¢–ë", "brand": "–ê–¢–ë"}'},
        {"name": "–°—ñ–ª—å–ø–æ", "shop": "supermarket"},
        None
    ]
    
    for tags in test_cases:
        result = parser.parse_tags(tags)
        print(f"  –í—Ö—ñ–¥: {tags}")
        print(f"  –†–µ–∑—É–ª—å—Ç–∞—Ç: name={result.name}, shop={result.shop_type}")
        print()

def test_brand_dictionary():
    """–¢–µ—Å—Ç Brand Dictionary"""
    print("\nüß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è Brand Dictionary...")
    
    brand_dict = BrandDictionary()
    stats = brand_dict.get_brand_statistics()
    
    print(f"  –í—Å—å–æ–≥–æ –±—Ä–µ–Ω–¥—ñ–≤: {stats['total_brands']}")
    print(f"  –í—Å—å–æ–≥–æ —Å–∏–Ω–æ–Ω—ñ–º—ñ–≤: {stats['total_synonyms']}")
    print(f"  –ó–∞ –≥—Ä—É–ø–∞–º–∏: {stats['by_functional_group']}")
    
    # –¢–µ—Å—Ç –ø–æ—à—É–∫—É
    test_names = ["–ê–¢–ë", "–ï–ø—ñ—Ü–µ–Ω—Ç—Ä", "Pizza Day"]
    print("\n  –¢–µ—Å—Ç –ø–æ—à—É–∫—É:")
    for name in test_names:
        result = brand_dict.find_brand_by_name(name)
        if result:
            brand_id, info = result
            print(f"    '{name}' ‚Üí {info.canonical_name} (ID: {brand_id})")
        else:
            print(f"    '{name}' ‚Üí –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ")

def test_brand_matcher():
    """–¢–µ—Å—Ç Brand Matcher"""
    print("\nüß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è Brand Matcher...")
    
    matcher = BrandMatcher()
    
    # –¢–µ—Å—Ç–æ–≤—ñ –≤–∏–ø–∞–¥–∫–∏
    test_cases = [
        ("–ê–¢–ë-–º–∞—Ä–∫–µ—Ç", None),
        ("—Å–∏–ª–ø–æ", {"shop": "supermarket"}),
        ("McDonald's", {"amenity": "fast_food", "brand": "McDonald's"}),
        ("–ù–µ–≤—ñ–¥–æ–º–∏–π –º–∞–≥–∞–∑–∏–Ω", None)
    ]
    
    for name, tags in test_cases:
        result = matcher.match_brand(name, tags)
        if result:
            print(f"  '{name}' ‚Üí {result.canonical_name}")
            print(f"    –î–æ–≤—ñ—Ä–∞: {result.confidence:.2f}, –¢–∏–ø: {result.match_type}")
            print(f"    –í–ø–ª–∏–≤: {result.influence_weight}, –ì—Ä—É–ø–∞: {result.functional_group}")
        else:
            print(f"  '{name}' ‚Üí –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
        print()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = matcher.get_statistics()
    print(f"\n  –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ matcher:")
    print(f"    –í—Å—å–æ–≥–æ –∑–∞–ø–∏—Ç—ñ–≤: {stats['total_requests']}")
    print(f"    –£—Å–ø—ñ—à–Ω–∏—Ö: {stats['successful_matches']}")
    print(f"    –¢–∏–ø–∏: {stats['match_types']}")

def test_database_connection():
    """–¢–µ—Å—Ç –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î"""
    print("\nüß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î...")
    
    import psycopg2
    import os
    
    db_string = os.getenv(
        'DB_CONNECTION_STRING',
        "postgresql://georetail_user:georetail_secure_2024@localhost:5432/georetail"
    )
    
    try:
        conn = psycopg2.connect(db_string)
        cur = conn.cursor()
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞–±–ª–∏—Ü—å
        cur.execute("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'osm_ukraine' 
            AND table_name IN ('poi_processed', 'h3_analytics_current', 'h3_analytics_changes')
            ORDER BY table_name;
        """)
        
        tables = [row[0] for row in cur.fetchall()]
        print(f"  –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü—ñ: {tables}")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–∞–Ω–∏—Ö –≤ osm_raw
        cur.execute("""
            SELECT COUNT(*) 
            FROM osm_ukraine.osm_raw 
            WHERE tags IS NOT NULL
        """)
        count = cur.fetchone()[0]
        print(f"  –ó–∞–ø–∏—Å—ñ–≤ –≤ osm_raw –∑ —Ç–µ–≥–∞–º–∏: {count:,}")
        
        cur.close()
        conn.close()
        print("  ‚úÖ –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è —É—Å–ø—ñ—à–Ω–µ!")
        
    except Exception as e:
        print(f"  ‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    print("=" * 60)
    print("üöÄ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤ Module 2")
    print("=" * 60)
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ —Ç–µ—Å—Ç–∏
    test_tag_parser()
    test_brand_dictionary()
    test_brand_matcher()
    test_database_connection()
    
    print("\n‚úÖ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("\n–ù–∞—Å—Ç—É–ø–Ω—ñ –∫—Ä–æ–∫–∏:")
    print("1. –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –æ–±—Ä–æ–±–∫—É –¥–∞–Ω–∏—Ö –∑ osm_raw")
    print("2. –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤ poi_processed")
    print("3. –ó–∞–ø—É—Å—Ç–∏—Ç–∏ —Ä–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ H3 –º–µ—Ç—Ä–∏–∫")

if __name__ == "__main__":
    main()