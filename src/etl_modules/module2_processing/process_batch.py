#!/usr/bin/env python3
"""
Batch processing script –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö –∑ osm_raw
"""

import sys
from pathlib import Path
import psycopg2
from psycopg2.extras import RealDictCursor
import logging
from datetime import datetime
import uuid

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –î–æ–¥–∞—î–º–æ –ø–æ—Ç–æ—á–Ω—É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é –¥–æ path
sys.path.insert(0, str(Path(__file__).parent))

# –Ü–º–ø–æ—Ä—Ç–∏ –º–æ–¥—É–ª—ñ–≤
from normalization.tag_parser import TagParser
from normalization.brand_matcher import BrandMatcher

# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ connection string –Ω–∞–ø—Ä—è–º—É
DB_CONNECTION_STRING = "postgresql://georetail_user:georetail_secure_2024@localhost:5432/georetail"

class BatchProcessor:
    """–ü—Ä–æ—Ü–µ—Å–æ—Ä –¥–ª—è batch –æ–±—Ä–æ–±–∫–∏ POI"""
    
    def __init__(self, connection_string=None):
        self.connection_string = connection_string or DB_CONNECTION_STRING
        self.tag_parser = TagParser()
        self.brand_matcher = BrandMatcher()
        self.stats = {
            'processed': 0,
            'poi_found': 0,
            'brands_matched': 0,
            'errors': 0
        }
    
    def process_batch(self, limit=1000, region=None):
        """–û–±—Ä–æ–±–∫–∞ batch –∑–∞–ø–∏—Å—ñ–≤"""
        logger.info(f"üöÄ –ü–æ—á–∞—Ç–æ–∫ –æ–±—Ä–æ–±–∫–∏ batch (limit={limit}, region={region})")
        
        conn = psycopg2.connect(self.connection_string)
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        try:
            # –í–∏–±–∏—Ä–∞—î–º–æ –¥–∞–Ω—ñ –¥–ª—è –æ–±—Ä–æ–±–∫–∏
            base_query = """
                SELECT id, osm_id, tags, name, brand, 
                       ST_AsText(geom) as geom_wkt,
                       h3_res_7, h3_res_8, h3_res_9, h3_res_10,
                       region_name
                FROM osm_ukraine.osm_raw
                WHERE tags IS NOT NULL
                AND (
                    tags::text LIKE '%%shop%%' 
                    OR tags::text LIKE '%%amenity%%'
                    OR tags::text LIKE '%%brand%%'
                )
            """
            
            if region:
                query = base_query + f" AND region_name = '{region}' LIMIT {limit}"
                logger.info(f"üìä –í–∏–±—ñ—Ä–∫–∞ –¥–∞–Ω–∏—Ö –∑ —Ä–µ–≥—ñ–æ–Ω—É {region}...")
                cur.execute(query)
            else:
                query = base_query + f" LIMIT {limit}"
                logger.info(f"üìä –í–∏–±—ñ—Ä–∫–∞ –¥–∞–Ω–∏—Ö...")
                cur.execute(query)
            
            rows = cur.fetchall()
            logger.info(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(rows)} –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è –æ–±—Ä–æ–±–∫–∏")
            
            # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–µ–Ω –∑–∞–ø–∏—Å
            processed_entities = []
            
            for i, row in enumerate(rows):
                if i % 100 == 0:
                    logger.info(f"  –û–±—Ä–æ–±–ª–µ–Ω–æ {i}/{len(rows)} –∑–∞–ø–∏—Å—ñ–≤...")
                
                try:
                    entity = self.process_row(row)
                    if entity:
                        processed_entities.append(entity)
                        self.stats['poi_found'] += 1
                except Exception as e:
                    logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∑–∞–ø–∏—Å—É {row['id']}: {e}")
                    self.stats['errors'] += 1
                
                self.stats['processed'] += 1
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            if processed_entities:
                logger.info(f"üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è {len(processed_entities)} –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö POI...")
                self.save_entities(conn, processed_entities)
            
            # –í–∏–≤–æ–¥–∏–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            logger.info("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–æ–±–∫–∏:")
            logger.info(f"  –û–±—Ä–æ–±–ª–µ–Ω–æ –∑–∞–ø–∏—Å—ñ–≤: {self.stats['processed']}")
            logger.info(f"  –ó–Ω–∞–π–¥–µ–Ω–æ POI: {self.stats['poi_found']}")
            logger.info(f"  –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ –±—Ä–µ–Ω–¥—ñ–≤: {self.stats['brands_matched']}")
            logger.info(f"  –ü–æ–º–∏–ª–æ–∫: {self.stats['errors']}")
            
        finally:
            cur.close()
            conn.close()
    
    def process_row(self, row):
        """–û–±—Ä–æ–±–∫–∞ –æ–¥–Ω–æ–≥–æ –∑–∞–ø–∏—Å—É"""
        # –ü–∞—Ä—Å–∏–º–æ —Ç–µ–≥–∏
        parsed_tags = self.tag_parser.parse_tags(row['tags'])
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
        primary_cat, secondary_cat = self.tag_parser.get_category_from_tags(parsed_tags.tags)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –Ω–µ-POI
        if primary_cat in ['road', 'building', 'landuse', 'other']:
            return None
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –Ω–∞–∑–≤—É
        name = parsed_tags.name or row.get('name')
        if not name:
            return None
        
        # –ú–∞—Ç—á–∏–º–æ –±—Ä–µ–Ω–¥
        brand_result = self.brand_matcher.match_brand(
            name=name,
            osm_tags=parsed_tags.tags
        )
        
        if brand_result:
            self.stats['brands_matched'] += 1
        
        # –§–æ—Ä–º—É—î–º–æ entity
        entity = {
            'entity_id': str(uuid.uuid4()),
            'osm_id': row['osm_id'],
            'osm_raw_id': row['id'],
            'entity_type': 'poi',
            'primary_category': primary_cat,
            'secondary_category': secondary_cat,
            'name_original': name,
            'name_standardized': name,  # TODO: –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –Ω–∞–∑–≤–∏
            'brand_normalized': brand_result.canonical_name if brand_result else None,
            'brand_confidence': brand_result.confidence if brand_result else 0.0,
            'brand_match_type': brand_result.match_type if brand_result else 'none',
            'functional_group': brand_result.functional_group if brand_result else self._get_default_group(primary_cat),
            'influence_weight': brand_result.influence_weight if brand_result else 0.0,
            'geom_wkt': row['geom_wkt'],
            'h3_res_7': row['h3_res_7'],
            'h3_res_8': row['h3_res_8'],
            'h3_res_9': row['h3_res_9'],
            'h3_res_10': row['h3_res_10'],
            'quality_score': 0.8 if brand_result else 0.5,  # TODO: —Ä–µ–∞–ª—å–Ω–∏–π quality scoring
            'region_name': row['region_name'],
            'processing_timestamp': datetime.now(),
            'processing_version': '2.0.0'
        }
        
        return entity
    
    def _get_default_group(self, category):
        """–í–∏–∑–Ω–∞—á–∞—î —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—É –≥—Ä—É–ø—É –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º"""
        if category == 'retail':
            return 'competitor'
        elif category in ['food_service', 'financial', 'healthcare']:
            return 'traffic_generator'
        elif category == 'transport':
            return 'accessibility'
        else:
            return 'neutral'
    
    def save_entities(self, conn, entities):
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è entities –≤ –ë–î"""
        cur = conn.cursor()
        saved_count = 0
        
        insert_query = """
            INSERT INTO osm_ukraine.poi_processed (
                entity_id, osm_id, osm_raw_id, entity_type,
                primary_category, secondary_category,
                name_original, name_standardized,
                brand_normalized, brand_confidence, brand_match_type,
                functional_group, influence_weight,
                geom, h3_res_7, h3_res_8, h3_res_9, h3_res_10,
                quality_score, region_name,
                processing_timestamp, processing_version
            ) VALUES (
                %(entity_id)s, %(osm_id)s, %(osm_raw_id)s, %(entity_type)s,
                %(primary_category)s, %(secondary_category)s,
                %(name_original)s, %(name_standardized)s,
                %(brand_normalized)s, %(brand_confidence)s, %(brand_match_type)s,
                %(functional_group)s, %(influence_weight)s,
                ST_GeomFromText(%(geom_wkt)s, 4326),
                %(h3_res_7)s, %(h3_res_8)s, %(h3_res_9)s, %(h3_res_10)s,
                %(quality_score)s, %(region_name)s,
                %(processing_timestamp)s, %(processing_version)s
            )
            ON CONFLICT (entity_id) DO NOTHING
        """
        
        for entity in entities:
            try:
                cur.execute(insert_query, entity)
                saved_count += 1
            except Exception as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è entity {entity['entity_id']}: {e}")
                conn.rollback()  # Rollback –¥–ª—è —Ü—å–æ–≥–æ –∑–∞–ø–∏—Å—É
                cur = conn.cursor()  # –ù–æ–≤–∏–π –∫—É—Ä—Å–æ—Ä
        
        conn.commit()
        cur.close()
        logger.info(f"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ {saved_count}/{len(entities)} entities")


def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Batch processing POI –∑ osm_raw')
    parser.add_argument('--limit', type=int, default=1000, help='–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è –æ–±—Ä–æ–±–∫–∏')
    parser.add_argument('--region', type=str, help='–û–±—Ä–æ–±–∏—Ç–∏ —Ç—ñ–ª—å–∫–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π —Ä–µ–≥—ñ–æ–Ω')
    
    args = parser.parse_args()
    
    processor = BatchProcessor()
    processor.process_batch(limit=args.limit, region=args.region)


if __name__ == "__main__":
    main()